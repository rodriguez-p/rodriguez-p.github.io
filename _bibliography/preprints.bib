@article{khanday_2025a,
	title = {Recreating Neural Activity During Speech Production with Language and Speech Model Embeddings},
	issn = {},
	url = {https://arxiv.org/abs/2505.14074},
	doi = {10.48550/arXiv.2505.14074},
	abstract= {Understanding how neural activity encodes speech and language production is a fundamental challenge in neuroscience and artificial intelligence. This study investigates whether embeddings from large-scale, self-supervised language and speech models can effectively reconstruct high-gamma neural activity characteristics, key indicators of cortical processing, recorded during speech production. We leverage pre-trained embeddings from deep learning models trained on linguistic and acoustic data to represent high-level speech features and map them onto these high-gamma signals. We analyze the extent to which these embeddings preserve the spatio-temporal dynamics of brain activity. Reconstructed neural signals are evaluated against high-gamma ground-truth activity using correlation metrics and signal reconstruction quality assessments. The results indicate that high-gamma activity can be effectively reconstructed using large language and speech model embeddings in all study participants, generating Pearson's correlation coefficients ranging from 0.79 to 0.99.},
	language = {en},
	urldate = {},
	journal = {arXiv},
	author = {Owais Mujtaba Khanday and Rodríguez-San Esteban, Pablo and Zubair Ahmad Lone and Marc Ouellet and José Andrés González-López},
	month = may,
	year = {2025},
	preprint = {https://arxiv.org/pdf/2505.14074},
}

@article{khanday_2025b,
	title = {UGR-MINDVOICE: A Multimodal EEG-Audio Dataset for Overt and Covert Iberian Spanish Speech Production},
	issn = {},
	url = {},
	doi = {},
	abstract= {We present UGR-MINDVOICE, the University of Granada (UGR) multi-modal electroencephalography (EEG) and audio dataset for overt and covert speech in Iberian spanish intended for basic neuroscience and brain-computer interface (BCI) research. The dataset features EEG and audio recordings from 15 native Spanish speakers engaged in both overt and covert speech production tasks. This dataset is unique in its inclusion of all Spanish phonemes and a diverse set of words spanning various semantic categories and different usage frequencies. Validation of the dataset confirmed the presence of the P100 event-related potential component, a distinct positive peak occurring around 100 milliseconds after visual stimulus onset, indicating participant attention to the visual stimuli. Additionally, the EEG data were classified into rest, covert speech, and overt speech conditions with an accuracy of 75.26%, demonstrating active participant engagement in the tasks. By providing synchronized EEG and audio data for overt speech, along with EEG data for the same stimuli during covert speech, UGR-MINDVOICE constitutes a valuable resource for advancing research in basic neuroscience and brain-computer interfaces, particularly in the domain of silent speech communication.},
	language = {en},
	urldate = {},
	journal = {},
	author = {Ibon Vales Cortina and Owais Mujtaba Khanday and Marc Ouellet and José Luis Pérez-Córdoba and Rodríguez-San Esteban, Pablo and Laura Miccoli and Alberto Galdón and Gonzalo Olivares Granados and José Andrés González-López},
	month = may,
	year = {2025},
	preprint = {},
}
