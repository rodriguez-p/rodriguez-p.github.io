@article{khanday_2025b,
	title = {UGR-MINDVOICE: A Multimodal EEG-Audio Dataset for Overt and Covert Iberian Spanish Speech Production},
	issn = {},
	url = {},
	doi = {},
	abstract= {We present UGR-MINDVOICE, the University of Granada (UGR) multi-modal electroencephalography (EEG) and audio dataset for overt and covert speech in Iberian spanish intended for basic neuroscience and brain-computer interface (BCI) research. The dataset features EEG and audio recordings from 15 native Spanish speakers engaged in both overt and covert speech production tasks. This dataset is unique in its inclusion of all Spanish phonemes and a diverse set of words spanning various semantic categories and different usage frequencies. Validation of the dataset confirmed the presence of the P100 event-related potential component, a distinct positive peak occurring around 100 milliseconds after visual stimulus onset, indicating participant attention to the visual stimuli. Additionally, the EEG data were classified into rest, covert speech, and overt speech conditions with an accuracy of 75.26%, demonstrating active participant engagement in the tasks. By providing synchronized EEG and audio data for overt speech, along with EEG data for the same stimuli during covert speech, UGR-MINDVOICE constitutes a valuable resource for advancing research in basic neuroscience and brain-computer interfaces, particularly in the domain of silent speech communication.},
	language = {en},
	urldate = {},
	journal = {},
	author = {Ibon Vales Cortina and Owais Mujtaba Khanday and Marc Ouellet and José Luis Pérez-Córdoba and Rodríguez-San Esteban, Pablo and Laura Miccoli and Alberto Galdón and Gonzalo Olivares Granados and José Andrés González-López},
	month = may,
	year = {2025},
	preprint = {},
}
